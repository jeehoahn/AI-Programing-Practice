{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/data-science-in-your-pocket/text-summarization-using-textrank-in-nlp-4bce52c5b390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainopenai pypdf unstructured[pdf] gensim newspaper numpy nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.document_loaders import OnlinePDFLoader # Unstructured[pdf]가 필요한 이유\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import networkx as nx\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 기사 한 개 크롤링\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "url=\"https://abcnews.go.com/US/live-updates/trump-fraud-trial/?id=103642561\"\n",
    "driver.get(url)\n",
    "page_source=driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "text=soup.find('div', class_='ScrollSpy_container').text\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화, 불용어처리 등\n",
    "sentences=sent_tokenize(text)\n",
    "sentences_clean=[re.sub(r'[^\\w\\s]','',sentence) for sentence in sentences]\n",
    "\n",
    "# nltk.download('stopwords') #이 작업을 수행할 필요는 한번\n",
    "\n",
    "stop_words = stopwords.words('english') \n",
    "sentence_tokens=[[words for words in sentence.split(' ') if words not in stop_words] for sentence in sentences_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장의 임베딩을 구하고 그 임베딩 값들이 같게 만드는 과정\n",
    "w2v = Word2Vec(sentence_tokens, vector_size=1, min_count=1, epochs=1000)\n",
    "sentence_embeddings=[[w2v.wv[word][0] for word in words] for words in sentence_tokens]\n",
    "max_len=max([len(tokens) for tokens in sentence_tokens])\n",
    "sentence_embeddings=[np.pad(embedding,(0,max_len-len(embedding)),'constant') for embedding in sentence_embeddings]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Rank가 기존에 입력받은 내용을 사용해서 요약하는 방법이다<br>\n",
    "### Page Rank는 어떠한 사이트와 링크로 연결된 사이트들의 유사도를 구해 검색 결과 순서를 정하는 방법이다<br>\n",
    "### 앞으로 우리는 Text Rank와 비슷한 Page Rank를 사용해서 Text Rank를 쓴 것처럼 결과를 낼 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 자리에 페이지가 들어가야하지만 문장을 넣는다\n",
    "# 문장의 수*문장의 수 크기인 두 개의 문장의 유사도가 있는 그래프를 구하기\n",
    "similarity_matrix = np.zeros([len(sentence_tokens), len(sentence_tokens)])\n",
    "for i,row_embedding in enumerate(sentence_embeddings):\n",
    "    for j,column_embedding in enumerate(sentence_embeddings):\n",
    "        similarity_matrix[i][j]=1-spatial.distance.cosine(row_embedding,column_embedding)\n",
    "nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "scores = nx.pagerank(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judge David Friedman of the appellate division's First Department stayed the order on Thursday, citing constitutional concerns over Trump's free speech rights.Engoron's filing includes a report from Charles Hollon of the Judicial Threats Assessment Unit of the New York State Court System’s Department of Public Safety.\n",
      "“However, when Mr. Trump violated the gag orders, the number of threatening, harassing and disparaging messages increased.”Engoron’s lawyer, Lisa Evans, said the threats detailed in Hollon's affirmation justify the gag order, which functions as a reasonable limit on free speech.\n",
      "Judge David Friedman of the appellate division's First Department stayed the order on Thursday, citing constitutional concerns over Trump's free speech rights.James' court filing Wednesday alleges that Trump and his lawyers continue to harass Engoron’s law clerk \"as part of an improper tactic to disrupt trial and undermine the proceedings.\n",
      "\"I never had anything to do with the statement of financial condition,\" Eric Trump testified, before partially walking back his statement to say, regarding notes that McConney requested from him, \"I don't think that it ever registered it was for a personal statement of financial condition.\n"
     ]
    }
   ],
   "source": [
    "# 가장 중요한 키워드 문장 top4 입력\n",
    "top_sentence={sentence:scores[index] for index,sentence in enumerate(sentences)}\n",
    "top=dict(sorted(top_sentence.items(), key=lambda x: x[1], reverse=True)[:4])\n",
    "for sent in sentences:\n",
    "    if sent in top.keys():\n",
    "        print(sent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
